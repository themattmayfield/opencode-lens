{"version":3,"file":"tokenizer.js","names":["stable: ThemedToken[]","unstable: ThemedToken[]"],"sources":["../../src/shiki-stream/tokenizer.ts"],"sourcesContent":["import type { GrammarState, ThemedToken } from '@shikijs/core';\n\nimport type {\n  ShikiStreamTokenizerEnqueueResult,\n  ShikiStreamTokenizerOptions,\n} from './types';\n\nexport class ShikiStreamTokenizer {\n  public readonly options: ShikiStreamTokenizerOptions;\n\n  public tokensStable: ThemedToken[] = [];\n  public tokensUnstable: ThemedToken[] = [];\n\n  public lastUnstableCodeChunk: string = '';\n  public lastStableGrammarState: GrammarState | undefined;\n\n  constructor(options: ShikiStreamTokenizerOptions) {\n    this.options = options;\n  }\n\n  /**\n   * Enqueue a chunk of code to the buffer.\n   */\n  // eslint-disable-next-line @typescript-eslint/require-await\n  async enqueue(chunk: string): Promise<ShikiStreamTokenizerEnqueueResult> {\n    const chunkLines = (this.lastUnstableCodeChunk + chunk).split('\\n');\n\n    const stable: ThemedToken[] = [];\n    let unstable: ThemedToken[] = [];\n    const recall = this.tokensUnstable.length;\n\n    chunkLines.forEach((line, i) => {\n      const isLastLine = i === chunkLines.length - 1;\n\n      const result = this.options.highlighter.codeToTokens(line, {\n        ...this.options,\n        grammarState: this.lastStableGrammarState,\n      });\n      const tokens = result.tokens[0]; // only one line\n      if (!isLastLine) tokens.push({ content: '\\n', offset: 0 });\n\n      if (!isLastLine) {\n        this.lastStableGrammarState = result.grammarState;\n        stable.push(...tokens);\n      } else {\n        unstable = tokens;\n        this.lastUnstableCodeChunk = line;\n      }\n    });\n\n    this.tokensStable.push(...stable);\n    this.tokensUnstable = unstable;\n\n    return {\n      recall,\n      stable,\n      unstable,\n    };\n  }\n\n  close(): { stable: ThemedToken[] } {\n    const stable = this.tokensUnstable;\n    this.tokensUnstable = [];\n    this.lastUnstableCodeChunk = '';\n    this.lastStableGrammarState = undefined;\n    return {\n      stable,\n    };\n  }\n\n  clear(): void {\n    this.tokensStable = [];\n    this.tokensUnstable = [];\n    this.lastUnstableCodeChunk = '';\n    this.lastStableGrammarState = undefined;\n  }\n\n  clone(): ShikiStreamTokenizer {\n    const clone = new ShikiStreamTokenizer(this.options);\n    clone.lastUnstableCodeChunk = this.lastUnstableCodeChunk;\n    clone.tokensUnstable = this.tokensUnstable;\n    clone.tokensStable = this.tokensStable;\n    clone.lastStableGrammarState = this.lastStableGrammarState;\n    return clone;\n  }\n}\n"],"mappings":";AAOA,IAAa,uBAAb,MAAa,qBAAqB;CAChC,AAAgB;CAEhB,AAAO,eAA8B,EAAE;CACvC,AAAO,iBAAgC,EAAE;CAEzC,AAAO,wBAAgC;CACvC,AAAO;CAEP,YAAY,SAAsC;AAChD,OAAK,UAAU;;;;;CAOjB,MAAM,QAAQ,OAA2D;EACvE,MAAM,cAAc,KAAK,wBAAwB,OAAO,MAAM,KAAK;EAEnE,MAAMA,SAAwB,EAAE;EAChC,IAAIC,WAA0B,EAAE;EAChC,MAAM,SAAS,KAAK,eAAe;AAEnC,aAAW,SAAS,MAAM,MAAM;GAC9B,MAAM,aAAa,MAAM,WAAW,SAAS;GAE7C,MAAM,SAAS,KAAK,QAAQ,YAAY,aAAa,MAAM;IACzD,GAAG,KAAK;IACR,cAAc,KAAK;IACpB,CAAC;GACF,MAAM,SAAS,OAAO,OAAO;AAC7B,OAAI,CAAC,WAAY,QAAO,KAAK;IAAE,SAAS;IAAM,QAAQ;IAAG,CAAC;AAE1D,OAAI,CAAC,YAAY;AACf,SAAK,yBAAyB,OAAO;AACrC,WAAO,KAAK,GAAG,OAAO;UACjB;AACL,eAAW;AACX,SAAK,wBAAwB;;IAE/B;AAEF,OAAK,aAAa,KAAK,GAAG,OAAO;AACjC,OAAK,iBAAiB;AAEtB,SAAO;GACL;GACA;GACA;GACD;;CAGH,QAAmC;EACjC,MAAM,SAAS,KAAK;AACpB,OAAK,iBAAiB,EAAE;AACxB,OAAK,wBAAwB;AAC7B,OAAK,yBAAyB;AAC9B,SAAO,EACL,QACD;;CAGH,QAAc;AACZ,OAAK,eAAe,EAAE;AACtB,OAAK,iBAAiB,EAAE;AACxB,OAAK,wBAAwB;AAC7B,OAAK,yBAAyB;;CAGhC,QAA8B;EAC5B,MAAM,QAAQ,IAAI,qBAAqB,KAAK,QAAQ;AACpD,QAAM,wBAAwB,KAAK;AACnC,QAAM,iBAAiB,KAAK;AAC5B,QAAM,eAAe,KAAK;AAC1B,QAAM,yBAAyB,KAAK;AACpC,SAAO"}